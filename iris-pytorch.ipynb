{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/hyPFbLhBD/SQUWlEm8te",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jammy-bot/keras-to-pytorch/blob/features/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6LlAZc2W-Gg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from urllib.request import urlretrieve"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAznf_cFXk9m"
      },
      "source": [
        "# reading the dataset\n",
        "iris = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "urlretrieve(iris)\n",
        "df = pd.read_csv(iris, sep=',')\n",
        "\n",
        "# adding column names to the dataframe\n",
        "df.columns = [\"sepal_length\", \"sepal_width\", \n",
        "              \"petal_length\", \"petal_width\", \n",
        "              \"species\"]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dIYNfPU5a39z",
        "outputId": "be4f0b58-efb5-4541-e511-c81858a6f0e0"
      },
      "source": [
        "# viewing a random sample of rows from the dataframe\n",
        "df.sample(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>6.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.3</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width          species\n",
              "96            6.2          2.9           4.3          1.3  Iris-versicolor\n",
              "110           6.4          2.7           5.3          1.9   Iris-virginica\n",
              "26            5.2          3.5           1.5          0.2      Iris-setosa\n",
              "141           5.8          2.7           5.1          1.9   Iris-virginica\n",
              "61            6.0          2.2           4.0          1.0  Iris-versicolor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7RpWJo-ZjPH"
      },
      "source": [
        "# converting to numpy\n",
        "x = df[[\"sepal_length\", \"sepal_width\", \n",
        "        \"petal_length\", \"petal_width\"]].values\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(df[\"species\"])\n",
        "species = le.classes_"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LRhn-qifZU4",
        "outputId": "1791107d-058f-4c4a-dcbc-be17531977ed"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149 entries, 0 to 148\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  149 non-null    float64\n",
            " 1   sepal_width   149 non-null    float64\n",
            " 2   petal_length  149 non-null    float64\n",
            " 3   petal_width   149 non-null    float64\n",
            " 4   species       149 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 5.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExPwtZQeaR_j"
      },
      "source": [
        "# splitting into validation and training sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.25, random_state = 42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3GJqnkc9xi"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUMi02p9c9xi"
      },
      "source": [
        "# Build neural network\n",
        "# model = Sequential()\n",
        "# model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "# model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "# model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# model.fit(x_train,y_train,verbose=2,epochs=100)\n",
        "\n",
        "# import pytorch library and modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo6EI0BCqKzW"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, output_count):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_count, 50) # first hidden layer\n",
        "        self.fc2 = nn.Linear(50, 25) # 50 form hidden1 to 25 in hidden2\n",
        "        self.fc3 = nn.Linear(25, output_count)\n",
        "        self.LogSoftmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return self.LogSoftmax(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXR83YMcssKw"
      },
      "source": [
        "# converting data to pytorch tensors\n",
        "x_train= Variable(torch.Tensor(x_train).float())\n",
        "x_test= Variable(torch.Tensor(x_test).float())\n",
        "\n",
        "# converting class indexes\n",
        "y_train= Variable(torch.LongTensor(y_train))\n",
        "y_test= Variable(torch.LongTensor(y_test))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07c0YQxLt1xf",
        "outputId": "57c16d60-c6a5-469b-9507-4fb3a7dda6ee"
      },
      "source": [
        "# instantiating the model\n",
        "model = Net(x.shape[1], len(species)) # number of columns, rows\n",
        "criterion = nn.CrossEntropyLoss() # declaring the loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(),  # parameters are the weights\n",
        "                             lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x_train)\n",
        "    loss = criterion(out, y_train)\n",
        "    loss.backward() # backward propagation\n",
        "    optimizer.step() # applying the gradients\n",
        "    print(f\"Epoch: {epoch+1}, loss: {loss.item()}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 1.4045157432556152\n",
            "Epoch: 2, loss: 1.0766183137893677\n",
            "Epoch: 3, loss: 1.0201165676116943\n",
            "Epoch: 4, loss: 0.980073094367981\n",
            "Epoch: 5, loss: 0.9165154695510864\n",
            "Epoch: 6, loss: 0.8034027814865112\n",
            "Epoch: 7, loss: 0.7558691501617432\n",
            "Epoch: 8, loss: 0.7355009913444519\n",
            "Epoch: 9, loss: 0.6813400387763977\n",
            "Epoch: 10, loss: 0.613172173500061\n",
            "Epoch: 11, loss: 0.5616206526756287\n",
            "Epoch: 12, loss: 0.5187031030654907\n",
            "Epoch: 13, loss: 0.4823765456676483\n",
            "Epoch: 14, loss: 0.46467944979667664\n",
            "Epoch: 15, loss: 0.44847372174263\n",
            "Epoch: 16, loss: 0.4167915880680084\n",
            "Epoch: 17, loss: 0.38802486658096313\n",
            "Epoch: 18, loss: 0.37125128507614136\n",
            "Epoch: 19, loss: 0.3462538421154022\n",
            "Epoch: 20, loss: 0.31348881125450134\n",
            "Epoch: 21, loss: 0.2895593047142029\n",
            "Epoch: 22, loss: 0.2662048041820526\n",
            "Epoch: 23, loss: 0.2374628633260727\n",
            "Epoch: 24, loss: 0.21806937456130981\n",
            "Epoch: 25, loss: 0.19758391380310059\n",
            "Epoch: 26, loss: 0.1732998788356781\n",
            "Epoch: 27, loss: 0.1594133973121643\n",
            "Epoch: 28, loss: 0.1415640413761139\n",
            "Epoch: 29, loss: 0.12740503251552582\n",
            "Epoch: 30, loss: 0.11789776384830475\n",
            "Epoch: 31, loss: 0.10469110310077667\n",
            "Epoch: 32, loss: 0.09903156757354736\n",
            "Epoch: 33, loss: 0.09071356803178787\n",
            "Epoch: 34, loss: 0.08534146100282669\n",
            "Epoch: 35, loss: 0.08127763122320175\n",
            "Epoch: 36, loss: 0.07542362809181213\n",
            "Epoch: 37, loss: 0.07318487018346786\n",
            "Epoch: 38, loss: 0.06803736835718155\n",
            "Epoch: 39, loss: 0.06581942737102509\n",
            "Epoch: 40, loss: 0.06228067725896835\n",
            "Epoch: 41, loss: 0.059593357145786285\n",
            "Epoch: 42, loss: 0.05768510326743126\n",
            "Epoch: 43, loss: 0.05481264740228653\n",
            "Epoch: 44, loss: 0.05379292741417885\n",
            "Epoch: 45, loss: 0.0512368269264698\n",
            "Epoch: 46, loss: 0.05033739656209946\n",
            "Epoch: 47, loss: 0.048363182693719864\n",
            "Epoch: 48, loss: 0.0472395196557045\n",
            "Epoch: 49, loss: 0.04579288884997368\n",
            "Epoch: 50, loss: 0.04448101669549942\n",
            "Epoch: 51, loss: 0.04341869428753853\n",
            "Epoch: 52, loss: 0.042008575052022934\n",
            "Epoch: 53, loss: 0.041191261261701584\n",
            "Epoch: 54, loss: 0.03983398899435997\n",
            "Epoch: 55, loss: 0.03912612050771713\n",
            "Epoch: 56, loss: 0.03789185360074043\n",
            "Epoch: 57, loss: 0.03726787865161896\n",
            "Epoch: 58, loss: 0.03616618737578392\n",
            "Epoch: 59, loss: 0.035582996904850006\n",
            "Epoch: 60, loss: 0.034621670842170715\n",
            "Epoch: 61, loss: 0.03408660739660263\n",
            "Epoch: 62, loss: 0.03323353826999664\n",
            "Epoch: 63, loss: 0.03273504972457886\n",
            "Epoch: 64, loss: 0.03198450431227684\n",
            "Epoch: 65, loss: 0.031527694314718246\n",
            "Epoch: 66, loss: 0.03085661493241787\n",
            "Epoch: 67, loss: 0.030432991683483124\n",
            "Epoch: 68, loss: 0.029838548973202705\n",
            "Epoch: 69, loss: 0.029448259621858597\n",
            "Epoch: 70, loss: 0.028920214623212814\n",
            "Epoch: 71, loss: 0.028554707765579224\n",
            "Epoch: 72, loss: 0.028090879321098328\n",
            "Epoch: 73, loss: 0.027748489752411842\n",
            "Epoch: 74, loss: 0.027343807741999626\n",
            "Epoch: 75, loss: 0.02701861411333084\n",
            "Epoch: 76, loss: 0.026667604222893715\n",
            "Epoch: 77, loss: 0.026358557865023613\n",
            "Epoch: 78, loss: 0.026055390015244484\n",
            "Epoch: 79, loss: 0.025761371478438377\n",
            "Epoch: 80, loss: 0.025497132912278175\n",
            "Epoch: 81, loss: 0.025219060480594635\n",
            "Epoch: 82, loss: 0.024985158815979958\n",
            "Epoch: 83, loss: 0.02472543530166149\n",
            "Epoch: 84, loss: 0.024512752890586853\n",
            "Epoch: 85, loss: 0.02427305467426777\n",
            "Epoch: 86, loss: 0.02407357469201088\n",
            "Epoch: 87, loss: 0.02385544404387474\n",
            "Epoch: 88, loss: 0.023663870990276337\n",
            "Epoch: 89, loss: 0.023466527462005615\n",
            "Epoch: 90, loss: 0.02328001707792282\n",
            "Epoch: 91, loss: 0.023100731894373894\n",
            "Epoch: 92, loss: 0.02291939966380596\n",
            "Epoch: 93, loss: 0.022753670811653137\n",
            "Epoch: 94, loss: 0.022579917684197426\n",
            "Epoch: 95, loss: 0.022422289475798607\n",
            "Epoch: 96, loss: 0.022259920835494995\n",
            "Epoch: 97, loss: 0.022106632590293884\n",
            "Epoch: 98, loss: 0.021955059841275215\n",
            "Epoch: 99, loss: 0.021805036813020706\n",
            "Epoch: 100, loss: 0.021661510691046715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Ae86GEc9xj"
      },
      "source": [
        "# Evaluate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXW6iEemc9xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d53f40-3a54-4c0a-db16-969802f94edd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pred = model(x_test)\n",
        "# dunder to ignore the first parameter\n",
        "_ , predict_classes = torch.max(pred,1) # np.argmax(pred,axis=1)\n",
        "# expected_classes = np.argmax(y_test,axis=1)\n",
        "\n",
        "correct = accuracy_score(y_test, predict_classes) # (expected_classes,predict_classes)\n",
        "print(f\"Accuracy: {correct}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P57Rx9v0c9xj"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}
